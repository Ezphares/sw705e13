\section{Implemented Testing Method}
\label{sec:test_method}

The following section will describe how we set up the testing environment for our users, how we created our test, and how we intend to analyze the data.
Finally we will describe the limitations of our testing experience, and why we tested the way we did.

\subsection{The Set-up}

The test will be conducted by requesting a server from the University to host our game, which will then be accessible to the outside world by visiting the website $www.simonjensen.net$.
Making the game available to the entire world ensures, that we have a high chance of getting many people to test our game, which gives the test much more of a quantitative advantage, than necessarily a qualitative advantage.

\subsection{Testing the System - Game System Experience}

We have decided to utilize \textbf{Unit Tests} to check that the code works as intended.
The more code we are able to unit test, the more we ensure a high code coverage on our tests, thus satisfying two schools from the game
experience evaluation box.

\subsection{Testing the Player - Individual Player Experience}

Given the test is going to be accessible to the entire world, a quantitative evaluation seems the most appropriate. Therefore we have chosen to use questionnaires and interviews (/other written feedback) which we request from the users when they have played our game, by following a link to a survey. Furthermore, given we advertise this test on various internet forums, user comments on these will also be taken into consideration for our evaluation.

\subsection{Limitations of our Test Method}

When we take into account the GX method, it is apparent to us, that there are things we cannot test for, since it is both out of scope for this project and the university may not be able to provide the needed technology.
For example, we do not include testing of player context.
It would only be viable for us to test, how well the game plays while on-the-move, in terms of whether the lights and colors on the screen are clear enough.
However hiring an expert in the field to aid with cultural debugging is out of scope, when the target group for this project does not imply cultural differences.
Furthermore, the game in its current state does not work on a mobile platform.

In terms of evaluating the player, it is not possible for us to set up a psycophysiological test, as that would demand access to hardware that we do not currently posses. We have chosen a quantitative testing method over a qualitative method, which means that we will not have direct access to conversations with our testers, and understand in greater depth their issues with the program. Furthermore, we cannot guarantee that every tester, actually fills out the questionnaire. Therefore we are very dependent on, they fill out the survey, after playing the game. In return however, we get a much more informal testing method for our players, and we hope the great accessibility will compensate and uncover the more obvious problems with our software.

\subsection{Questionnaire}

The questionnaire is based around a 'rating-approach', letting people chose between various levels of agreement for each question. We feel this approach is faster for a tester to fill out, and gives more freedom in how they chose to reply. Of course, letting the players entirely describe each answer in detail, is an option as well, but this may be too daunting and time consuming for users, when they are asked to test in this informal and casual way our test-setup suggests. The questionnaire can be seen in the appendix at: \autoref{app:questionnaire}.